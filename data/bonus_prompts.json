[
  {
    "Task": "Full-File Bug Detection and Refactoring (Python)",
    "Zero-Shot": "Analyze the following utility script. Identify any potential logic issues or design flaws. Then, refactor it for better readability, correctness, and safety.\n\n# utils.py - Script to parse and summarize numeric CSV files\nimport csv\ndef read_csv(filepath):\n  with open(filepath, 'r') as f:\n    return [row for row in csv.reader(f)]\ndef summarize_column(data, index):\n  values = [float(row[index]) for row in data[1:]]  # skip header\n  total = sum(values)\n  avg = total / len(values)\n  return total, avg\ndef main():\n  filepath = 'data.csv'\n  data = read_csv(filepath)\n  total, avg = summarize_column(data, 1)\n  print(\"Total:\", total)\n  print(\"Average:\", avg)\nif __name__ == '__main__':\n  main()",
    "Few-Shot": "Analyze the following utility script. Identify any potential logic issues or design flaws. Then, refactor it for better readability, correctness, and safety.\n\n# utils.py - Script to parse and summarize numeric CSV files\nimport csv\ndef read_csv(filepath):\n  with open(filepath, 'r') as f:\n    return [row for row in csv.reader(f)]\ndef summarize_column(data, index):\n  values = [float(row[index]) for row in data[1:]]  # skip header\n  total = sum(values)\n  avg = total / len(values)\n  return total, avg\ndef main():\n  filepath = 'data.csv'\n  data = read_csv(filepath)\n  total, avg = summarize_column(data, 1)\n  print(\"Total:\", total)\n  print(\"Average:\", avg)\nif __name__ == '__main__':\n  main()\n\nExample 1:\nI've identified several issues with this script:\n\n1. Error handling: The script doesn't handle file not found errors, invalid data, or empty columns.\n2. Hardcoded values: The filepath and column index are hardcoded rather than configurable.\n3. Type safety: There's no validation that the data contains numeric values.\n4. Documentation: The code lacks docstrings and comments.\n\nHere's my refactored version:\n\n```python\n# utils.py - Script to parse and summarize numeric CSV files\nimport csv\nimport sys\nfrom typing import List, Tuple, Any\n\ndef read_csv(filepath: str) -> List[List[str]]:\n    \"\"\"Read a CSV file and return its contents as a list of rows.\n    \n    Args:\n        filepath: Path to the CSV file\n        \n    Returns:\n        List of rows, where each row is a list of strings\n        \n    Raises:\n        FileNotFoundError: If the file doesn't exist\n    \"\"\"\n    try:\n        with open(filepath, 'r') as f:\n            return list(csv.reader(f))\n    except FileNotFoundError:\n        print(f\"Error: File {filepath} not found.\")\n        raise\n\ndef summarize_column(data: List[List[str]], index: int) -> Tuple[float, float]:\n    \"\"\"Calculate the sum and average of a numeric column in the data.\n    \n    Args:\n        data: List of rows from a CSV file\n        index: Index of the column to summarize (0-based)\n        \n    Returns:\n        Tuple containing (total, average) for the column\n        \n    Raises:\n        IndexError: If the column index is out of range\n        ValueError: If the column contains non-numeric values\n        ZeroDivisionError: If the data has no rows (excluding header)\n    \"\"\"\n    if not data or len(data) <= 1:\n        raise ValueError(\"Data must have at least one row plus a header\")\n    \n    if index < 0 or (data and index >= len(data[0])):\n        raise IndexError(f\"Column index {index} is out of range\")\n    \n    try:\n        values = [float(row[index]) for row in data[1:]]  # skip header\n        if not values:\n            raise ValueError(\"No numeric values found in column (excluding header)\")\n        \n        total = sum(values)\n        avg = total / len(values)\n        return total, avg\n    except ValueError as e:\n        if \"could not convert string to float\" in str(e):\n            print(f\"Error: Column {index} contains non-numeric values\")\n        raise\n\ndef main(filepath: str = None, column_index: int = None):\n    \"\"\"Parse and summarize a column from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file, defaults to 'data.csv'\n        column_index: Index of the column to summarize (0-based), defaults to 1\n    \"\"\"\n    # Use command line arguments or defaults\n    filepath = filepath or (sys.argv[1] if len(sys.argv) > 1 else 'data.csv')\n    column_index = column_index or (int(sys.argv[2]) if len(sys.argv) > 2 else 1)\n    \n    try:\n        data = read_csv(filepath)\n        total, avg = summarize_column(data, column_index)\n        print(f\"Column: {data[0][column_index] if data and data[0] else column_index}\")\n        print(f\"Total: {total:.2f}\")\n        print(f\"Average: {avg:.2f}\")\n    except (FileNotFoundError, IndexError, ValueError, ZeroDivisionError) as e:\n        print(f\"Error: {e}\")\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\nThis refactored version includes:\n- Proper error handling for file operations and data processing\n- Command-line argument support with sensible defaults\n- Type hints for better code understanding\n- Comprehensive docstrings explaining function purposes\n- Safer numeric conversion with error handling\n- Formatted output for better readability\n\nExample 2:\nI've analyzed the utility script and found several issues:\n\n1. No error handling - The script doesn't handle missing files, invalid data formats, or edge cases\n2. Hardcoded filepath - 'data.csv' is hardcoded in main(), making the script inflexible\n3. No validation - The script assumes column 1 exists and contains numeric data\n4. Division by zero risk - If data has only a header row, len(values) will be 0\n5. No proper documentation or type hints\n\nHere's my refactored version:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Utility script to parse and summarize numeric data from CSV files.\"\"\"\n\nimport csv\nimport os\nimport sys\nfrom typing import List, Tuple, Optional\n\n\ndef read_csv(filepath: str) -> List[List[str]]:\n    \"\"\"Read data from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file\n        \n    Returns:\n        A list of rows, where each row is a list of strings\n        \n    Raises:\n        FileNotFoundError: If the file doesn't exist\n    \"\"\"\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n        \n    with open(filepath, 'r', newline='') as f:\n        return list(csv.reader(f))\n\n\ndef summarize_column(data: List[List[str]], index: int) -> Tuple[float, float]:\n    \"\"\"Calculate the sum and average of values in a specified column.\n    \n    Args:\n        data: CSV data as a list of rows\n        index: Column index to summarize (0-based)\n        \n    Returns:\n        A tuple containing (total, average)\n        \n    Raises:\n        IndexError: If the column index is out of bounds\n        ValueError: If the column contains non-numeric values\n        ValueError: If there's no data to average (empty dataset)\n    \"\"\"\n    if not data:\n        raise ValueError(\"Empty dataset provided\")\n        \n    if len(data) <= 1:\n        raise ValueError(\"Dataset contains only headers, no values to summarize\")\n    \n    # Validate column index\n    if index < 0 or index >= len(data[0]):\n        raise IndexError(f\"Column index {index} is out of bounds for data with {len(data[0])} columns\")\n    \n    try:\n        # Convert values to float, skipping the header row\n        values = [float(row[index]) for row in data[1:] if row[index].strip()]\n        \n        if not values:\n            raise ValueError(f\"No valid numeric values found in column {index}\")\n            \n        total = sum(values)\n        avg = total / len(values)\n        return total, avg\n    except ValueError as e:\n        if \"could not convert string to float\" in str(e):\n            raise ValueError(f\"Column {index} contains non-numeric values\")\n        raise\n\n\ndef parse_args() -> Tuple[str, int]:\n    \"\"\"Parse command line arguments or use defaults.\n    \n    Returns:\n        Tuple of (filepath, column_index)\n    \"\"\"\n    filepath = 'data.csv'  # Default filepath\n    column_index = 1       # Default column index\n    \n    if len(sys.argv) > 1:\n        filepath = sys.argv[1]\n    if len(sys.argv) > 2:\n        try:\n            column_index = int(sys.argv[2])\n        except ValueError:\n            print(f\"Error: Column index must be an integer, got '{sys.argv[2]}'\")\n            sys.exit(1)\n            \n    return filepath, column_index\n\n\ndef main() -> None:\n    \"\"\"Main function to process CSV and display column statistics.\"\"\"\n    filepath, column_index = parse_args()\n    \n    try:\n        print(f\"Processing file: {filepath}, column: {column_index}\")\n        data = read_csv(filepath)\n        \n        # Get column name from header if available\n        column_name = data[0][column_index] if data and len(data[0]) > column_index else f\"Column {column_index}\"\n        \n        total, avg = summarize_column(data, column_index)\n        \n        print(f\"Column: {column_name}\")\n        print(f\"Total: {total:.2f}\")\n        print(f\"Average: {avg:.2f}\")\n        print(f\"Row count: {len(data) - 1}\")\n    except (FileNotFoundError, IndexError, ValueError) as e:\n        print(f\"Error: {e}\")\n        sys.exit(1)\n\n\nif __name__ == '__main__':\n    main()\n```\n\nImprovements in this refactored version:\n1. Added comprehensive error handling throughout the code\n2. Added proper type hints and docstrings\n3. Implemented command-line argument parsing\n4. Added validation for inputs and data formats\n5. Enhanced output with formatted values and additional information\n6. Made the code more robust against edge cases like empty files or non-numeric data\n7. Used proper CSV handling with newline='' parameter\n8. Added structure with clear function responsibilities"
  },
  {
    "Task": "Code Completion and Robustness Enhancement (Python)",
    "Zero-Shot": "Complete the following file-processing script. The goal is to clean each line, remove punctuation, and count word frequencies correctly.\n\n# file_processor.py - Incomplete script for processing text files\nimport string\ndef load_file(filepath):\n  with open(filepath, 'r') as f:\n    return f.readlines()\ndef clean_line(line):\n  # TODO: Remove punctuation and make lowercase\n  pass\ndef count_words(lines):\n  word_counts = {}\n  for line in lines:\n    clean = clean_line(line)\n    for word in clean.split():\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return word_counts\ndef main():\n  filepath = 'input.txt'\n  lines = load_file(filepath)\n  counts = count_words(lines)\n  for word, count in sorted(counts.items()):\n    print(f\"{word}: {count}\")\nif __name__ == '__main__':\n  main()",
    "Few-Shot": "Complete the following file-processing script. The goal is to clean each line, remove punctuation, and count word frequencies correctly.\n\n# file_processor.py - Incomplete script for processing text files\nimport string\ndef load_file(filepath):\n  with open(filepath, 'r') as f:\n    return f.readlines()\ndef clean_line(line):\n  # TODO: Remove punctuation and make lowercase\n  pass\ndef count_words(lines):\n  word_counts = {}\n  for line in lines:\n    clean = clean_line(line)\n    for word in clean.split():\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return word_counts\ndef main():\n  filepath = 'input.txt'\n  lines = load_file(filepath)\n  counts = count_words(lines)\n  for word, count in sorted(counts.items()):\n    print(f\"{word}: {count}\")\nif __name__ == '__main__':\n  main()\n\nExample 1:\nI'll complete the missing `clean_line` function and enhance the script for better robustness. Here's the completed version:\n\n```python\n# file_processor.py - Script for processing text files and counting word frequencies\nimport string\nimport sys\n\ndef load_file(filepath):\n    \"\"\"Load a text file and return its content as a list of lines.\n    \n    Args:\n        filepath: Path to the text file\n        \n    Returns:\n        List of strings, each representing a line in the file\n        \n    Raises:\n        FileNotFoundError: If the file doesn't exist\n    \"\"\"\n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            return f.readlines()\n    except FileNotFoundError:\n        print(f\"Error: File '{filepath}' not found.\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error reading file: {e}\")\n        sys.exit(1)\n\ndef clean_line(line):\n    \"\"\"Clean a line by removing punctuation and converting to lowercase.\n    \n    Args:\n        line: A string representing a line of text\n        \n    Returns:\n        Cleaned string with punctuation removed and all lowercase\n    \"\"\"\n    # Remove punctuation and make lowercase\n    translator = str.maketrans('', '', string.punctuation)\n    return line.translate(translator).lower().strip()\n\ndef count_words(lines):\n    \"\"\"Count frequency of each word in the provided lines.\n    \n    Args:\n        lines: List of strings, each representing a line of text\n        \n    Returns:\n        Dictionary mapping words to their frequency counts\n    \"\"\"\n    word_counts = {}\n    for line in lines:\n        clean = clean_line(line)\n        for word in clean.split():\n            if word:  # Skip empty strings\n                word_counts[word] = word_counts.get(word, 0) + 1\n    return word_counts\n\ndef main():\n    \"\"\"Main function to process text file and display word counts.\"\"\"\n    # Get filepath from command line arguments or use default\n    filepath = sys.argv[1] if len(sys.argv) > 1 else 'input.txt'\n    \n    print(f\"Processing file: {filepath}\")\n    lines = load_file(filepath)\n    \n    counts = count_words(lines)\n    \n    if not counts:\n        print(\"No words found in the file.\")\n        return\n    \n    print(f\"Found {len(counts)} unique words:\")\n    for word, count in sorted(counts.items()):\n        print(f\"{word}: {count}\")\n\nif __name__ == '__main__':\n    main()\n```\n\nKey improvements:\n1. Implemented the `clean_line` function to remove punctuation and convert text to lowercase\n2. Added error handling for file operations\n3. Added support for command-line arguments to specify the input file\n4. Added skipping of empty strings after cleaning and splitting\n5. Added informative output messages\n6. Added docstrings for better code documentation\n7. Used UTF-8 encoding to support international characters\n\nExample 2:\nI've completed the script by implementing the `clean_line` function and improving the code's robustness. Here's the enhanced version:\n\n```python\n#!/usr/bin/env python3\n\"\"\"File processor script that cleans text and counts word frequencies.\"\"\"\n\nimport string\nimport sys\nimport os\nfrom collections import Counter\n\ndef load_file(filepath):\n    \"\"\"Load a text file and return its content as a list of lines.\n    \n    Args:\n        filepath: Path to the text file to process\n        \n    Returns:\n        List of strings where each string is a line from the file\n        \n    Raises:\n        FileNotFoundError: If the specified file doesn't exist\n    \"\"\"\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n        \n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            return f.readlines()\n    except UnicodeDecodeError:\n        # Try again with a different encoding if UTF-8 fails\n        with open(filepath, 'r', encoding='latin-1') as f:\n            return f.readlines()\n\ndef clean_line(line):\n    \"\"\"Remove punctuation from a line and convert to lowercase.\n    \n    Args:\n        line: String representing a line of text\n        \n    Returns:\n        Cleaned string with no punctuation and all lowercase characters\n    \"\"\"\n    # Create a translation table to remove all punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    \n    # Remove punctuation, convert to lowercase, and strip whitespace\n    cleaned = line.translate(translator).lower().strip()\n    \n    # Replace multiple spaces with a single space\n    cleaned = ' '.join(cleaned.split())\n    \n    return cleaned\n\ndef count_words(lines):\n    \"\"\"Count the frequency of each word in the given lines.\n    \n    Args:\n        lines: List of text lines to process\n        \n    Returns:\n        Dictionary mapping words to their frequency counts\n    \"\"\"\n    word_counts = {}\n    for line in lines:\n        if not line.strip():  # Skip empty lines\n            continue\n            \n        clean = clean_line(line)\n        for word in clean.split():\n            if word:  # Skip empty strings\n                word_counts[word] = word_counts.get(word, 0) + 1\n    return word_counts\n\ndef parse_args():\n    \"\"\"Parse command line arguments.\n    \n    Returns:\n        String representing the filepath to process\n    \"\"\"\n    if len(sys.argv) > 1:\n        return sys.argv[1]\n    return 'input.txt'  # Default filepath\n\ndef main():\n    \"\"\"Main function to process a text file and print word frequencies.\"\"\"\n    try:\n        filepath = parse_args()\n        print(f\"Processing file: {filepath}\")\n        \n        lines = load_file(filepath)\n        print(f\"Loaded {len(lines)} lines\")\n        \n        counts = count_words(lines)\n        print(f\"Found {len(counts)} unique words\")\n        \n        if not counts:\n            print(\"No words found in the file.\")\n            return\n        \n        # Get the top 10 most common words\n        most_common = Counter(counts).most_common(10)\n        print(\"\\nTop 10 most common words:\")\n        for word, count in most_common:\n            print(f\"{word}: {count}\")\n        \n        print(\"\\nAll words in alphabetical order:\")\n        for word, count in sorted(counts.items()):\n            print(f\"{word}: {count}\")\n            \n    except FileNotFoundError as e:\n        print(f\"Error: {e}\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\nImprovements made:\n1. Implemented the `clean_line` function to remove punctuation and convert text to lowercase\n2. Added comprehensive error handling throughout the code\n3. Added support for different file encodings\n4. Added filtering to skip empty lines and words\n5. Included command-line argument support\n6. Used the Counter class to efficiently find the most common words\n7. Added detailed output information including stats about processed lines and unique words\n8. Added proper docstrings and comments for better code documentation\n9. Normalized whitespace by replacing multiple spaces with a single space\n10. Added graceful error handling with informative messages"
  }
] 